\chapter{Introdução}

O uso de técnicas de processamento de sinais podem facilitar a análise e
classificação de dados, podendo ser utilizadas em um campo abrangente de áreas
do conhecimento, citando como exemplos a medicina e bolsa de valores.

Em certos casos a elevada taxa de dados pode ser um problema, sendo necessário a
utilização de um sistema de filtragem. Essa ferramenta realiza a seleção dos dados 
de interesse, de modo a eliminar aqueles que não agregam informações relevantes 
para o caso em questão. Essa tarefa se torna ainda mais difícil nos casos do evento 
de interesse ser raro, sendo necessário otimizar o sistema de filtragem de modo que 
ele seja capaz de detectar com precisão tais eventos, ao mesmo tempo que descarta 
com eficiência a informação inútil ao problema em questão, reduzindo assim a dimensão 
de eventos, sem desprezar a parte interessante dos mesmos.
Podem ser utilizados tanto métodos baseados no conhecimento especialista do
assunto, quanto métodos baseados na informação estatística do processo, 
que frequentemente filtram com maior qualidade os dados de interesse. Ainda, 
a combinação do conhecimento especialista ao processamento 
estatístico trás uma abordagem ainda mais poderosa, através da utilização das informações 
em técnicas não lineares, como redes neurais.

O sistema de filtragem pode ser utilizado no ambiente {\it online},
quando o processo de seleção ocorre durante a aquisição de dados. Nesse ambiente
deseja-se reduzir o volume de dados a serem armazenados. A decisão deve ser realizada 
em curtos espaços de tempo, de maneira que atenda a taxa esperada de geração de
dados, e ainda ser eficiente, uma vez que não se terá mais acesso aos dados
rejeitados. No ambiente {\it online} é possível o processamento dos dados em série
ou em paralelo. O processamento em série limita o tempo de processamento àquele
de aquisição dos dados, não sendo interessante quando há flutuação do
processamento dos eventos. Por outro lado, o processamento em
paralelo possibilita que eventos mais complexos ocorram durante um tempo maior
que a taxa de aquisição de dados. Nesse tipo de processamento é necessário que
todos os eventos tenham um tempo de latência(tempo máximo de processamento), determinado pela capacidade
de processamento, para evitar gargalos no sistema de filtragem.

Já no ambiente {\it offline} o processo de seleção pode ser mais
complexo, uma vez que ele não está imbuído de realizar a decisão atendendo os
requisitos de tempo do ambiente {\it online}, e espera-se que ele um sistema
tenha melhor eficiência quando atuando em {\it offline}.

\section{Motivação} 

O CERN (Centro Europeu para Pesquisas Nucleares) é o maior centro de
pesquisas em física de partículas do mundo, situado na fronteira da Suíça com a
França \cite{webCERN}. O experimento de grande repercussão do CERN se consiste no LHC ({\it
Large Hadron Collider}), um acelerador de partículas de 27km de
circunferência que irá atingir energias nunca antes obtidas
experimentalmente \cite{webLHC}. 
Nesse ambiente de colaboração internacional estarão presentes
todas as características de um sistema de alta taxa de dados e raros eventos de
interesse.

Serão acelerados pacotes de prótons em feixes com sentidos opostos no LHC,
ocorrendo colisões em quatro pontos, com uma frequência de 40MHz. Nesses pontos, são instalados 
detectores de partículas que observam o subproduto das colisões dos pacotes de prótons 
acelerados pelo LHC. O ATLAS é um dos detectores do LHC, sendo construído e operado por 
uma colaboração internacional envolvendo 174 institutos de 38
países \cite{webATLAS}. Ele foi projetado 
de modo a atender a diversos requisitos da física experimental atual e por isso é dito de uso
geral. Para atendê-los ele é dividido nos seguintes sub-detectores:

\begin{itemize}
\item Detector de traços, responsável pela detecção da trajetória de partículas carregadas;
\item Calorímetro Eletromagnético, cujo objetivo é realizar a absorção total da
energia de partículas eletromagnéticas;
\item Calorímetro Hadrônico, que de maneira similar ao eletromagnético realiza a
absorção da energia de partículas hadrônicas;
\item Detector de Múons, para a identificação e determinação da trajetória de
Múons.
\end{itemize}

A física estudada nesse experimento é muito rara, podendo ser observados algumas
poucas vezes ao longo de vários dias de colisão. Um dos objetivos para o qual o
ATLAS foi designado é a identificação da partícula bóssom de Higgs, única partícula 
do modelo padrão ainda não observada. Estima-se que cerca de 17 k dessas
partículas (para a massa de 500 GeV) deverão ser produzidas por ano, comparados
com o total de $1.7\times10^{16}$ eventos produzidos de colisões inelásticas \cite{resumo_ATLAS}. 

Para a taxa de colisão de 40 MHz são esperadas cerca de 1 GHz de iterações quando
operando nas condições nominais. Nessas condições estima-se para cada evento de colisão 
cerca de aproximadamente 1.5 MB de espaço em disco rígido. Desta forma, 
o fluxo de dados no decorrer do experimento será de 60 TB/s, impossibilitando o
armazenamento completo dos eventos ocorridos no experimento. 

Assim é natural a adoção de um sistema de filtragem {\it online} para a
identificação dos eventos de interesse a serem armazenados, reduzindo os 1GHz
para cerca de 100Hz. O sistema de filtragem do ATLAS realiza o processamento dos 
eventos em paralelo, estando dividido em três níveis sequenciais, onde cada um 
analisa o evento com maior complexidade.

\begin{itemize}
\item O primeiro nível de filtragem realiza a filtragem com FPGA (circuitos
integrados com portas lógicas) usando resolução reduzida das células do detector
com um tempo fixo de 2 $\mu$s, reduzindo a taxa de eventos para
75 kHz. Ele também é responsável pela identificação de regiões no detector onde
há informação relevante, referidas como região de interesse (RoI). Somente a
informação contida nessa região é propagada para o segundo nível, de forma a
minimizar o fluxo de dados no sistema.
\item O segundo nível analisa somente os eventos que passaram pelas condições do
primeiro nível. Utiliza a resolução total das células do detector, 
tendo um tempo de latência de 10 ms, de maneira a reduzir a taxa de eventos para
1kHz. É implementado em linguagens de alto nível como C++ e python para sua configuração. 
Para esse nível são disponíveis cerca de 500 processadores, com quatro
núcleos de processamento, conectados em rede.
\item O terceiro nível, além de avaliar com maior acurácia aqueles que foram
selecionados pelo segundo nível, realiza a procura por eventos não identificados pelo
primeiro nível por causa de sua menor resolução. Ele possui um tempo de 
latência de 10 s, reduzindo a taxa de eventos para 100 Hz. Utiliza a mesma
infraestrutura computacional do segundo nível, entretanto tem disponíveis 1900 processadores.
\end{itemize}

Uma vez o evento sendo aceito pelo terceiro nível, o mesmo é então armazenado
para futura analise pelos algoritmos desenvolvidos para analise em {\it
offline}.

Um dos canais de interesse do experimento, o canal elétron/fóton (e/$\gamma$),
deseja identificar elétrons (e$^-$), pósitrons (e$^+$) ou fótons ($\gamma$), 
partículas de componentes eletromagnéticas. Muitos dos decaímentos do bóssom de
Higgs serão nessas partículas, de forma que esse canal é de fundamental
importância para o experimento. Ainda, a partícula $J/\Psi$, partícula importante
para a determinação da resolução em baixa energia do detector, 
também decai em elétrons, sendo assim um objeto de estudo nesse canal.
Jatos, partículas onde componentes hadrônicas são predominantes, 
mascaram a assinatura das partículas desejadas pelo canal e/$\gamma$, fazendo 
com que a tarefa da identificação dessas partículas não seja trivial.

\section{Objetivo} % {{{

O objetivo deste trabalho é otimizar o \emph{Egamma Calorimeter Ringer},
um algoritmo alternativo que vem sido desenvolvido pelo LPS (Laboratório 
de Processamento de Sinais) para realizar a discriminação 
no canal e/$\gamma$. Tal algoritmo foi idealizado para o segundo
nível de filtragem do detector ATLAS, sendo implementado na colaboração em 2005.
Nele a informação de calorimetria é tratada através do conhecimento especialista
e então propagada para um método estatístico 
de discriminação, onde atualmente é utilizado redes neurais. 
Para que tal melhoria seja alcançada no
algoritmo será realizado um estudo de preprocessamento dos dados,
através da escolha da melhor normalização a ser adotada.

Ainda, um dos requisitos para a adesão do algoritmo no sistema de filtragem é a
implementação de uma versão do mesmo para o ambiente de analise em {\it
offline}, de maneira  que a colaboração possa utilizá-lo e entender o seu
funcionamento. Por esse motivo, também se faz necessário a implementação 
da nova versão para a complexa estrutura de código desse ambiente.

Por fim, é necessária uma analise da eficiência do algoritmo para ambos os
ambientes, utilizando como parâmetro seus equivalentes desenvolvidos pela colaboração.

 % }}}
\section{Organização do documento} % {{{

O capítulo 2 apresenta o contexto de colaboração internacional no qual o projeto
foi desenvolvido, dando a base necessária para o entendimento do experimento. No
capítulo 3, são especificados os algoritmos de filtragem desenvolvidos para o
canal e/$\gamma$, assim como os detalhes de implementação do algoritmo
\emph{offline}. No capítulo 4 são apresentado os resultados para a analise de
normalização e a eficiência da versão {\it online} algoritmo, enquanto no
capítulo 5 são apresentados os resultados de performance para a versão {\it
offline} do algoritmo. 
sistema é usado pela colaboração no capítulo 6. Por fim, o capítulo 7 apresenta
as conclusões do trabalho e os possíveis desdobramentos.

% }}}
